"""Welcome to Pynecone! This file outlines the steps to create a basic app."""

# Import pynecone.
import openai
import os
from datetime import datetime

import pynecone as pc
from pynecone.base import Base

from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate
from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate



CUR_DIR = os.path.dirname(os.path.abspath('chatbot'))
kakao_sync_txt = os.path.join(CUR_DIR, "data/project_data.txt")


# openai.api_key = "<YOUR_OPENAI_API_KEY>"
os.environ["OPENAI_API_KEY"] = open("./key.txt", "r").read()

# ì¹´ì¹´ì˜¤ì‹±í¬ íŒŒì¼ ì½ê¸° 
def read_prompt_template(file_path: str) -> str:
    with open(file_path, "r") as f:
        prompt_template = f.read()

    return prompt_template

# ì´ë ‡ê²Œ ë°›ì€ ë°ì´í„° ë‚´ìš©ì„ ì–´ë–»ê²Œ ì¢€ ì •ë¦¬í•˜ë©´ ì¢‹ì„ê¹Œ?
# ë”•ì…”ë„ˆë¦¬ë¡œ ì¢€ ë‚˜ëˆ ë†“ìœ¼ê¹Œ... 

# ë°›ì€ ë‚´ìš© ë””ë¹„ì— ì €ìž¥ 

# create_chain
def create_chain(llm, kakao_sync_txt, output_key):
    return LLMChain(
        llm=llm,
        prompt=ChatPromptTemplate.from_template(
            template=read_prompt_template(kakao_sync_txt),
        ),
        output_key=output_key,
        verbose=True, # ì–˜ë„¤ë“¤ì´ ì§„í–‰ë˜ëŠ” ìƒí™©ì„ í”„ë¦°íŠ¸ ë¬¸ìœ¼ë¡œ ì°ì–´ì¤Œ
    )


from langchain.chains import SequentialChain

def generate_answer(question) -> dict[str, str]:

  llm = ChatOpenAI(temperature=0.1, max_tokens=300, model="gpt-3.5-turbo-16k")

  # ì•„ì´ë””ì–´ ë½‘ê¸° ì²´ì¸ ìƒì„±
  answer_chain1 = create_chain(llm, kakao_sync_txt, "ë‹µë³€")

  preprocess_chain = SequentialChain( #SequentialChain ìˆœì„œëŒ€ë¡œ ì‹¤í–‰
      chains=[
          answer_chain1,
          #answer_chain2
      ],
      input_variables=["kakao_sync_txt", "question"],
      output_variables=["ë‹µë³€"],
      verbose=True,
  )

  context = dict(
      kakao_sync_txt=read_prompt_template(kakao_sync_txt),
      question=question,
  )
  context = preprocess_chain(context)
  '''
  context["novel_chapter"] = []
  for chapter_number in range(1, 3):
      context["chapter_number"] = chapter_number
      context = novel_chapter_chain(context)
      context["novel_chapter"].append(context["output"])
  '''
  #contents = "\n\n".join(context["novel_chapter"])
  #return {"results": contents}

  context = answer_chain1(context)

  return context["ë‹µë³€"]

# ë‹µë³€ ìš”ì•½ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€ 
# ë‹µë³€ ë²ˆí˜¸ ë§¤ê¸°ê¸° ì¶”ê°€ 
#question = "ì¹´ì¹´ì˜¤ì‹±í¬ ê¸°ëŠ¥ì´ ë¬´ì—‡ì´ ìžˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”"
#print(generate_answer(question))

def answer_using_chatgpt(user_input: str):
    print("create llm ...")
    llm = ChatOpenAI(temperature=0.1, max_tokens=300, model="gpt-3.5-turbo-16k")

    print("create prompt template ...")
    prompt_template = ChatPromptTemplate.from_messages(
        [
            SystemMessagePromptTemplate.from_template(
                f"""
                assistantëŠ” ì±—ë´‡ìœ¼ë¡œì„œ ë™ìž‘í•œë‹¤. ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•œë‹¤.

                ê°€ì´ë“œ
                '''
                {read_prompt_template(kakao_sync_txt)}
                '''
                """
            ),
            HumanMessagePromptTemplate.from_template("{question}")
        ]
    )

    print("create chain and run ...")
    chain = LLMChain(llm=llm, prompt=prompt_template)
    answer = chain.run(
        question=user_input,
        verbose=True
    )
    return answer


# llm ì •ì˜ 
#llm = ChatOpenAI(temperature=0.9, model_name='gpt-3.5-turbo-16k')


parallel_example = {
    "í•œêµ­ì–´": ["ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ", "ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ AIê¸°ìˆ ì´ ì¸ê¸°ë¥¼ëŒê³  ìžˆë‹¤."],
    "ì˜ì–´": ["How is the weather today", "Deep learning-based AI technology is gaining popularity."],
    "ì¼ë³¸ì–´": ["ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹", "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®AIãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼ãŒäººæ°—ã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚"]
}


def translate_text_using_text_davinci(text, src_lang, trg_lang) -> str: #text : í•œêµ­ë¬¸ìž¥ 
    response = openai.Completion.create(engine="text-davinci-003",
                                        prompt=f"Translate the following {src_lang} text to {trg_lang}: {text}",
                                        max_tokens=200,
                                        n=1,
                                        temperature=1
                                        )
    translated_text = response.choices[0].text.strip()
    return translated_text


def translate_text_using_chatgpt(text, src_lang, trg_lang) -> str:
    # fewshot ì˜ˆì œë¥¼ ë§Œë“¤ê³ 
    def build_fewshot(src_lang, trg_lang):
        src_examples = parallel_example[src_lang]
        trg_examples = parallel_example[trg_lang]

        fewshot_messages = [] # ë©”ì„¸ì§€ë¥¼ ì—¬ëŸ¬ê°œ ì§ˆë¬¸ í•˜ëŠ” ë°©ì‹ 

        for src_text, trg_text in zip(src_examples, trg_examples):
            fewshot_messages.append({"role": "user", "content": src_text})
            fewshot_messages.append({"role": "assistant", "content": trg_text})

        return fewshot_messages

    # system instruction ë§Œë“¤ê³ 
    system_instruction = f"assistantëŠ” ë²ˆì—­ì•±ìœ¼ë¡œì„œ ë™ìž‘í•œë‹¤. {src_lang}ë¥¼ {trg_lang}ë¡œ ì ì ˆí•˜ê²Œ ë²ˆì—­í•˜ê³  ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•œë‹¤." #ë¡¤ ì ìš© > ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ë²ˆì—­ì•± 

    # messagesë¥¼ë§Œë“¤ê³ 
    fewshot_messages = build_fewshot(src_lang=src_lang, trg_lang=trg_lang)

    messages = [{"role": "system", "content": system_instruction},
                *fewshot_messages, # í•œêµ­ì–´ ì˜ì–´ 
                {"role": "user", "content": text}
                ]

    # API í˜¸ì¶œ
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo",
                                            messages=messages)
    translated_text = response['choices'][0]['message']['content']
    # Return
    return translated_text




class Message(Base):
    original_text: str
    text: str
    created_at: str
    to_lang: str


class State(pc.State):
    """The app state."""

    text: str = ""
    messages: list[Message] = []
    src_lang: str = "í•œêµ­ì–´"
    trg_lang: str = "ì˜ì–´"

    @pc.var
    def output(self) -> str:
        if not self.text.strip():
            return "Translations will appear here."
        translated = translate_text_using_chatgpt(
            self.text, src_lang=self.src_lang, trg_lang=self.trg_lang)
        return answer_using_chatgpt(self.text)

    def post(self):
        self.messages = [
            Message(
                original_text=self.text,
                text=self.output,
                created_at=datetime.now().strftime("%B %d, %Y %I:%M %p"),
                to_lang=self.trg_lang,
            )
        ] + self.messages


# Define views.


def header():
    """Basic instructions to get started."""
    return pc.box(
        pc.text("Translator ðŸ—º", font_size="2rem"),
        pc.text(
            "Translate things and post them as messages!",
            margin_top="0.5rem",
            color="#666",
        ),
    )


def down_arrow():
    return pc.vstack(
        pc.icon(
            tag="arrow_down",
            color="#666",
        )
    )


def text_box(text):
    return pc.text(
        text,
        background_color="#fff",
        padding="1rem",
        border_radius="8px",
    )


def message(message):
    return pc.box(
        pc.vstack(
            text_box(message.original_text),
            down_arrow(),
            text_box(message.text),
            pc.box(
                pc.text(message.to_lang),
                pc.text(" Â· ", margin_x="0.3rem"),
                pc.text(message.created_at),
                display="flex",
                font_size="0.8rem",
                color="#666",
            ),
            spacing="0.3rem",
            align_items="left",
        ),
        background_color="#f5f5f5",
        padding="1rem",
        border_radius="8px",
    )


def smallcaps(text, **kwargs):
    return pc.text(
        text,
        font_size="0.7rem",
        font_weight="bold",
        text_transform="uppercase",
        letter_spacing="0.05rem",
        **kwargs,
    )


def output():
    return pc.box(
        pc.box(
            smallcaps(
                "Output",
                color="#aeaeaf",
                background_color="white",
                padding_x="0.1rem",
            ),
            position="absolute",
            top="-0.5rem",
        ),
        pc.text(State.output),
        padding="1rem",
        border="1px solid #eaeaef",
        margin_top="1rem",
        border_radius="8px",
        position="relative",
    )


def index():
    """The main view."""
    return pc.container(
        header(),
        pc.input(
            placeholder="Text to translate",
            on_blur=State.set_text,
            margin_top="1rem",
            border_color="#eaeaef"
        ),
        pc.select(
            list(parallel_example.keys()),
            value=State.src_lang,
            placeholder="Select a language",
            on_change=State.set_src_lang,
            margin_top="1rem",
        ),
        pc.select(
            list(parallel_example.keys()),
            value=State.trg_lang,
            placeholder="Select a language",
            on_change=State.set_trg_lang,
            margin_top="1rem",
        ),
        output(),
        pc.button("Post", on_click=State.post, margin_top="1rem"),
        pc.vstack(
            pc.foreach(State.messages, message),
            margin_top="2rem",
            spacing="1rem",
            align_items="left"
        ),
        padding="2rem",
        max_width="600px"
    )


# Add state and page to the app.
app = pc.App(state=State)
app.add_page(index, title="Translator")
app.compile()
